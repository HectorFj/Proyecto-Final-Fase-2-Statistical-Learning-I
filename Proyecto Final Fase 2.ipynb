{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c738fe-c687-44a6-b1e9-65196118bd0e",
   "metadata": {},
   "source": [
    "# Proyecto Final Fase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e96b54-ecd0-4109-bddf-3275b08bec61",
   "metadata": {},
   "source": [
    "##### Héctor Evelio Fajardo Jiménez 18001842\n",
    "##### Ana Marcela Bethancourt Vargas 09000253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5baaaf6-19fa-4642-9c6a-33a417f919a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "caab1ea0-ea6e-4955-9119-60d71102db91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instalación de paquetes\n",
    "# pip install scikit-learn xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa8dd383-7994-4a7e-9bfe-45955d5fefe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6845bf38-0ea5-48fd-a849-043716323696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "29587e21-02b6-46b3-b207-0d35a647202f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4144dd25-5ce0-4ef2-9fa0-030509a4d4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3703fdb9-ccab-4851-8eee-b1681df5f58a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance  Previous qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapf1 = pd.read_csv(\"datapf1.csv\")\n",
    "datapf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aaa6f70b-6841-468c-9a8b-fa3ac01171f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separar (X) y (y)\n",
    "X = datapf1.drop('Target', axis=1)\n",
    "y = datapf1['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f62f4025-b545-4a38-9d28-9a9ac1eaf91c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# Convertir clases a valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Identificar las columnas categóricas y numéricas\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Proceso para características numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Proceso para características categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Crear el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Preprocesamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb78b57-3063-443a-a410-9167506b671d",
   "metadata": {},
   "source": [
    "#### Guardar en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72f00934-a182-41b6-a854-35375ec2ba13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformar todo el dataset para guardarlo\n",
    "# X_transformed = preprocessor.transform(X)\n",
    "\n",
    "# Convertir el array transformado a un DataFrame\n",
    "#X_transformed_df = pd.DataFrame(X_transformed, columns=np.append(numeric_features, preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)))\n",
    "#X_transformed_df['Target'] = y\n",
    "\n",
    "# Guardar el DataFrame transformado a un archivo CSV\n",
    "#X_transformed_df.to_csv('transformed_datapf1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345dbb94-afd8-4d5e-b475-196f51e71713",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c7e5fb73-ef51-4383-b138-72bad9bbcbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[216  34  66]\n",
      " [ 28  38  85]\n",
      " [ 24  35 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       316\n",
      "           1       0.36      0.25      0.29       151\n",
      "           2       0.70      0.86      0.77       418\n",
      "\n",
      "    accuracy                           0.69       885\n",
      "   macro avg       0.62      0.60      0.60       885\n",
      "weighted avg       0.68      0.69      0.68       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Entrenar el modelo\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88e140-f17d-4554-b01b-a4d52219fe11",
   "metadata": {},
   "source": [
    "## b. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "30b1c7d9-0752-448b-91e1-268f7e6d98ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis Discriminante Lineal (LDA)\n",
      "[[217  43  56]\n",
      " [ 25  51  75]\n",
      " [  4  29 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77       316\n",
      "           1       0.41      0.34      0.37       151\n",
      "           2       0.75      0.92      0.82       418\n",
      "\n",
      "    accuracy                           0.74       885\n",
      "   macro avg       0.68      0.65      0.66       885\n",
      "weighted avg       0.74      0.74      0.73       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Entrenar el modelo\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "results = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': []}\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Análisis Discriminante Lineal (LDA)\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Añadir los resultados al diccionario\n",
    "results['Model'].append('LDA')\n",
    "results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "results['Precision'].append(np.mean(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['precision']))\n",
    "results['Recall'].append(np.mean(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['recall']))\n",
    "results['F1-Score'].append(np.mean(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba62f9b-605e-4291-8bf0-e225369b2bd1",
   "metadata": {},
   "source": [
    "## c. Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd64937f-ce5d-4959-8d1b-bb57b284a0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística\n",
      "[[244  27  45]\n",
      " [ 35  42  74]\n",
      " [ 14  24 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       316\n",
      "           1       0.45      0.28      0.34       151\n",
      "           2       0.76      0.91      0.83       418\n",
      "\n",
      "    accuracy                           0.75       885\n",
      "   macro avg       0.68      0.65      0.66       885\n",
      "weighted avg       0.73      0.75      0.74       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Entrenar el modelo\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Regresión Logística\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdedbc1-19ea-4fc0-87d6-edf607a4d05a",
   "metadata": {},
   "source": [
    "## d. SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "834800ac-2f8d-4fd9-a11f-98831a613aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "[[230  34  52]\n",
      " [ 23  48  80]\n",
      " [  7  18 393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       316\n",
      "           1       0.48      0.32      0.38       151\n",
      "           2       0.75      0.94      0.83       418\n",
      "\n",
      "    accuracy                           0.76       885\n",
      "   macro avg       0.70      0.66      0.67       885\n",
      "weighted avg       0.75      0.76      0.74       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Entrenar el modelo\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"SVM\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b785adf-8e64-4de1-9cc7-5be80e805611",
   "metadata": {},
   "source": [
    "## e. Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "90c54cff-ebf7-461f-b4fe-74457cecdb3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árboles de Decisión\n",
      "[[202  62  52]\n",
      " [ 33  61  57]\n",
      " [ 36  47 335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       316\n",
      "           1       0.36      0.40      0.38       151\n",
      "           2       0.75      0.80      0.78       418\n",
      "\n",
      "    accuracy                           0.68       885\n",
      "   macro avg       0.62      0.61      0.62       885\n",
      "weighted avg       0.68      0.68      0.68       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Entrenar el modelo\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Árboles de Decisión\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3ef60-b2c5-4fe2-a9a9-cfad708578be",
   "metadata": {},
   "source": [
    "## f. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b278c70c-0ec3-458b-a03b-1fb028a9082c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[[247  22  47]\n",
      " [ 35  50  66]\n",
      " [  8  20 390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82       316\n",
      "           1       0.54      0.33      0.41       151\n",
      "           2       0.78      0.93      0.85       418\n",
      "\n",
      "    accuracy                           0.78       885\n",
      "   macro avg       0.72      0.68      0.69       885\n",
      "weighted avg       0.76      0.78      0.76       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Random Forest\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df098c80-285a-413d-a781-f388d4899f5e",
   "metadata": {},
   "source": [
    "## g. Análisis de discriminante lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "307322ce-aec4-4525-ab13-a3b4ef9a14f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LDA es el B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb096f-4ea8-4359-b3fe-e85ac79d2ab7",
   "metadata": {},
   "source": [
    "## h. Análisis de discriminante cuadrático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c037a5fa-6959-4a62-908a-1822bea1af5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de Discriminante Cuadrático\n",
      "[[222  46  48]\n",
      " [ 32  55  64]\n",
      " [ 18  46 354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76       316\n",
      "           1       0.37      0.36      0.37       151\n",
      "           2       0.76      0.85      0.80       418\n",
      "\n",
      "    accuracy                           0.71       885\n",
      "   macro avg       0.65      0.64      0.64       885\n",
      "weighted avg       0.71      0.71      0.71       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Entrenar el modelo\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = qda.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Análisis de Discriminante Cuadrático\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc4f39-ab0d-473e-a134-cfef97fd1001",
   "metadata": {},
   "source": [
    "## i. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "48f04100-d841-49bd-a741-a45c9053d573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "[[237  35  44]\n",
      " [ 44  41  66]\n",
      " [ 19  19 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       316\n",
      "           1       0.43      0.27      0.33       151\n",
      "           2       0.78      0.91      0.84       418\n",
      "\n",
      "    accuracy                           0.74       885\n",
      "   macro avg       0.67      0.64      0.65       885\n",
      "weighted avg       0.72      0.74      0.73       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Entrenar el modelo\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"AdaBoost\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f29248-f829-4ca3-85d7-93adfa3f325f",
   "metadata": {},
   "source": [
    "## j. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "695081f7-5000-4cde-a6b3-b7a2cf31a1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[240  31  45]\n",
      " [ 39  48  64]\n",
      " [  8  24 386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       316\n",
      "           1       0.47      0.32      0.38       151\n",
      "           2       0.78      0.92      0.85       418\n",
      "\n",
      "    accuracy                           0.76       885\n",
      "   macro avg       0.69      0.67      0.67       885\n",
      "weighted avg       0.75      0.76      0.75       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Entrenar el modelo\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27face38-c23f-4824-bf32-b3ed5ad4954e",
   "metadata": {},
   "source": [
    "## k. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc830d28-acf9-4339-bce6-4b229525e4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[236  35  45]\n",
      " [ 32  65  54]\n",
      " [ 13  25 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       316\n",
      "           1       0.52      0.43      0.47       151\n",
      "           2       0.79      0.91      0.85       418\n",
      "\n",
      "    accuracy                           0.77       885\n",
      "   macro avg       0.72      0.70      0.70       885\n",
      "weighted avg       0.76      0.77      0.76       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Entrenar el modelo\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e17fa6-2210-4847-97c2-5e7e0eff98e6",
   "metadata": {},
   "source": [
    "## l. LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2f1fa405-95e8-4e21-9cb3-b1b4364ac454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1300\n",
      "[LightGBM] [Info] Number of data points in the train set: 3539, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.163999\n",
      "[LightGBM] [Info] Start training from score -1.705455\n",
      "[LightGBM] [Info] Start training from score -0.681070\n",
      "LGBM\n",
      "[[237  35  44]\n",
      " [ 33  59  59]\n",
      " [ 12  24 382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       316\n",
      "           1       0.50      0.39      0.44       151\n",
      "           2       0.79      0.91      0.85       418\n",
      "\n",
      "    accuracy                           0.77       885\n",
      "   macro avg       0.71      0.68      0.69       885\n",
      "weighted avg       0.76      0.77      0.76       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Entrenar el modelo\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"LGBM\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5edfa08-3842-4e79-be7a-bb0336ba9033",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluación y Comparación de los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d98f82c7-e0e8-4e66-8174-753de412807a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': ['Naive Bayes', 'Regresión Logística', 'LDA', 'SVM', 'Árboles de Decisión', 'Random Forest', 'QDA', 'AdaBoost', 'Gradient Boosting', 'XGBoost', 'LightGBM'], 'Accuracy': [0.6926553672316385, 0.752542372881356, 0.7378531073446327, 0.7581920903954802, 0.6757062146892655, 0.7762711864406779, 0.7129943502824859, 0.7435028248587571, 0.7615819209039548, 0.7694915254237288, 0.7661016949152543], 'Precision': [0.6808496622313589, 0.7340833505891269, 0.7381215463711595, 0.7513235239336935, 0.6837374816366255, 0.7630570309750271, 0.7140619706576649, 0.7220019054901176, 0.7464128346604858, 0.7633022976849878, 0.757404897248009], 'Recall': [0.6926553672316385, 0.752542372881356, 0.7378531073446327, 0.7581920903954802, 0.6757062146892655, 0.7762711864406779, 0.7129943502824859, 0.7435028248587571, 0.7615819209039548, 0.7694915254237288, 0.7661016949152543], 'F1-Score': [0.6798231949956989, 0.7363081777186452, 0.728637291494608, 0.7440918759181377, 0.6777068015120471, 0.7612924204400309, 0.7108799779372912, 0.726957083501547, 0.7480891952898038, 0.7628444517114099, 0.7574796999918997]}\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los resultados\n",
    "results_df = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': []}\n",
    "\n",
    "# Lista de modelos entrenados\n",
    "models = [\n",
    "    ('Naive Bayes', nb),\n",
    "    ('Regresión Logística', log_reg),\n",
    "    ('LDA', lda),\n",
    "    ('SVM', svm),\n",
    "    ('Árboles de Decisión', dt),\n",
    "    ('Random Forest', rf),\n",
    "    ('QDA', qda),\n",
    "    ('AdaBoost', ada),\n",
    "    ('Gradient Boosting', gb),\n",
    "    ('XGBoost', xgb),\n",
    "    ('LightGBM', lgbm)\n",
    "]\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for name, model in models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    results_df['Model'].append(name)\n",
    "    results_df['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    results_df['Precision'].append(np.mean(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['precision']))\n",
    "    results_df['Recall'].append(np.mean(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['recall']))\n",
    "    results_df['F1-Score'].append(np.mean(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']))\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62098ce0-57dd-4d3c-8d2d-b5f2eeaae0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo mismo de aqui arriba pero lo guarda en el CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "05799fe4-4335-40d4-a86b-c84ba816e4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:40:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1300\n",
      "[LightGBM] [Info] Number of data points in the train set: 3539, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.163999\n",
      "[LightGBM] [Info] Start training from score -1.705455\n",
      "[LightGBM] [Info] Start training from score -0.681070\n",
      "Los resultados se han guardado 'Modelo_evaluacion.csv'.\n",
      "                  Model  Accuracy  Precision    Recall  F1-Score  \\\n",
      "9               XGBoost  0.769492   0.763302  0.769492  0.762844   \n",
      "10             LightGBM  0.766102   0.757405  0.766102  0.757480   \n",
      "8     Gradient Boosting  0.764972   0.752242  0.764972  0.752399   \n",
      "5         Random Forest  0.763842   0.747989  0.763842  0.748452   \n",
      "3                   SVM  0.758192   0.751324  0.758192  0.744092   \n",
      "1   Regresión Logística  0.752542   0.734083  0.752542  0.736308   \n",
      "7              AdaBoost  0.743503   0.722002  0.743503  0.726957   \n",
      "2                   LDA  0.737853   0.738122  0.737853  0.728637   \n",
      "6                   QDA  0.712994   0.714062  0.712994  0.710880   \n",
      "0           Naive Bayes  0.692655   0.680850  0.692655  0.679823   \n",
      "4   Árboles de Decisión  0.679096   0.686266  0.679096  0.681595   \n",
      "\n",
      "              Timestamp  \n",
      "9   2024-06-27 11:40:09  \n",
      "10  2024-06-27 11:40:10  \n",
      "8   2024-06-27 11:40:08  \n",
      "5   2024-06-27 11:40:00  \n",
      "3   2024-06-27 11:39:57  \n",
      "1   2024-06-27 11:39:56  \n",
      "7   2024-06-27 11:40:01  \n",
      "2   2024-06-27 11:39:56  \n",
      "6   2024-06-27 11:40:00  \n",
      "0   2024-06-27 11:39:55  \n",
      "4   2024-06-27 11:39:57  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Entrenar y evaluar modelos\n",
    "models = [\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Regresión Logística', LogisticRegression(max_iter=1000)),\n",
    "    ('LDA', LinearDiscriminantAnalysis()),\n",
    "    ('SVM', SVC()),\n",
    "    ('Árboles de Decisión', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('QDA', QuadraticDiscriminantAnalysis()),\n",
    "    ('AdaBoost', AdaBoostClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')),\n",
    "    ('LightGBM', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# Para almacenar los resultados\n",
    "results_df = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': [], 'Timestamp': []}\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    results_df['Model'].append(name)\n",
    "    results_df['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    results_df['Precision'].append(report['weighted avg']['precision'])\n",
    "    results_df['Recall'].append(report['weighted avg']['recall'])\n",
    "    results_df['F1-Score'].append(report['weighted avg']['f1-score'])\n",
    "    results_df['Timestamp'].append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "# Ordenar el DataFrame por precisión\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "results_df.to_csv('Modelo_evaluacion.csv', index=False)\n",
    "\n",
    "print(\"Los resultados se han guardado 'Modelo_evaluacion.csv'.\")\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38dfd56-7062-4e9c-91b8-6cbe649c4f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d12862-b9cc-4777-b8cd-0a641fa36a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
